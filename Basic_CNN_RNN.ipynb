{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY1V78RPBVgn",
        "outputId": "57b39828-b042-4a06-8de4-9e7123c01b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from pytube import YouTube, exceptions\n",
        "import os\n",
        "import cv2\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KxKQE4ZeBXSw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json(file_name):\n",
        "    with open(file_name, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def load_data(path):\n",
        "  with open(path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "  filtered_data = [item for item in data if item['clean_text'] in classes.keys()]\n",
        "  # print(len(filtered_data))\n",
        "  for item in filtered_data:\n",
        "      item['url'] = 'w' + item['url'].lstrip('https://www.youtube.com')\n",
        "  return filtered_data\n",
        "\n",
        "def download_video(url, output_path, filename):\n",
        "    \"\"\"Downloads a video from YouTube.\"\"\"\n",
        "\n",
        "    file_path = os.path.join(output_path, filename)\n",
        "    # Skip download if file already exist\n",
        "    if os.path.exists(file_path):\n",
        "        return file_path\n",
        "\n",
        "    try:\n",
        "        yt = YouTube(url)\n",
        "        stream = yt.streams.get_highest_resolution()\n",
        "        stream.download(output_path=output_path, filename=filename)\n",
        "        return file_path\n",
        "    except exceptions.VideoPrivate:\n",
        "        return None\n",
        "    except exceptions.VideoUnavailable:\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def extract_and_preprocess_frames(url, start_time, end_time, fps, box, width, height):\n",
        "  local_video_path = download_video('https://www.youtube.com/' + url, './videos', url.split(\"=\")[1] + '.mp4')\n",
        "  if local_video_path is not None:\n",
        "    video = cv2.VideoCapture(local_video_path)\n",
        "  else:\n",
        "    return None\n",
        "  frames = []\n",
        "  frame_count = int((end_time - start_time) * fps)\n",
        "  video.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
        "\n",
        "  while len(frames) < frame_count:\n",
        "      ret, frame = video.read()\n",
        "      if not ret:\n",
        "          break\n",
        "      x_min = int(box[0] * width)\n",
        "      y_min = int(box[1] * height)\n",
        "      x_max = int(box[2] * width)\n",
        "      y_max = int(box[3] * height)\n",
        "      cropped_frame = frame[y_min:y_max, x_min:x_max]\n",
        "      # Resize frame\n",
        "      resized_frame = cv2.resize(cropped_frame, (128, 128))\n",
        "      # Normalize frame\n",
        "      normalized_frame = resized_frame.astype(np.float32) / 255.0\n",
        "      frames.append(normalized_frame)\n",
        "  return frames\n",
        "\n",
        "def preprocess_data(data):\n",
        "  processed_data = []\n",
        "  # count = 1\n",
        "  for video in data:\n",
        "    # print(f\"processing {count} videos\")\n",
        "    frames = extract_and_preprocess_frames(video['url'], video['start_time'],\n",
        "                                           video['end_time'], video['fps'],\n",
        "                                           video['box'], video['width'],\n",
        "                                           video['height'])\n",
        "    if frames is None:\n",
        "      continue\n",
        "    label = video['label']\n",
        "    processed_data.append({'label': label, 'frames': frames})\n",
        "\n",
        "    del frames  # Delete frames to free up memory\n",
        "    gc.collect()\n",
        "\n",
        "    # count += 1\n",
        "\n",
        "  return processed_data"
      ],
      "metadata": {
        "id": "VNICD74eBZFA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_data = load_json('./drive/MyDrive/csc413_project_data/MSASL_classes.json')\n",
        "classes = {word: idx for idx, word in enumerate(classes_data)}\n",
        "\n",
        "train_data = load_data('./drive/MyDrive/csc413_project_data/MSASL_train.json')\n",
        "test_data = load_data('./drive/MyDrive/csc413_project_data/MSASL_test.json')\n",
        "val_data = load_data('./drive/MyDrive/csc413_project_data/MSASL_val.json')\n",
        "\n",
        "train_data = preprocess_data(train_data)\n",
        "test_data = preprocess_data(test_data)\n",
        "val_data = preprocess_data(val_data)"
      ],
      "metadata": {
        "id": "2e_2H4rtBZtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Define a CNN model to extract features from each frame\n",
        "    cnn_base = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "    ])\n",
        "\n",
        "    # Define the full model that includes LSTM layers\n",
        "    model = Sequential([\n",
        "        TimeDistributed(cnn_base, input_shape=(None, 128, 128, 3)),\n",
        "        LSTM(64, return_sequences=True),\n",
        "        LSTM(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(len(classes), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model()"
      ],
      "metadata": {
        "id": "-1WxIoNoBf7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_plot(model, test_data):\n",
        "    test_loss, test_accuracy = model.evaluate(test_data['frames'], test_data['labels'], verbose=0)\n",
        "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "    # Predictions for confusion matrix\n",
        "    predictions = model.predict(test_data['frames'])\n",
        "    cm = confusion_matrix(test_data['labels'], np.argmax(predictions, axis=1))\n",
        "    sns.heatmap(cm, annot=True, fmt='d')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual labels')\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qp3esinDDr5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data, val_data, test_data, epochs=10, batch_size=1):\n",
        "    for epoch in range(epochs):\n",
        "        np.random.shuffle(data)  # Shuffle the data each epoch\n",
        "        for video in data:\n",
        "            frames = np.array([video['frames']])  # Shape: (1, num_frames, 224, 224, 3)\n",
        "            label = np.array([video['label']])\n",
        "            model.train_on_batch(frames, label)\n",
        "        evaluate_and_plot(model, val_data)\n",
        "    evaluate_and_plot(model, test_data)\n",
        "\n",
        "train_model(model, preprocess_data(train_data), preprocess_data(val_data), preprocess_data(test_data), epochs=1, batch_size=10)"
      ],
      "metadata": {
        "id": "hGWuR9a0Bj8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}